{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1742f8d3d00ca20",
   "metadata": {},
   "source": [
    "# 02 - Failing fits\n",
    "\n",
    "This tutorial shows examples of fits that fail and how to identify and fix the issue or avoid it in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef75ff88",
   "metadata": {},
   "source": [
    "## Data and model\n",
    "\n",
    "Let's use the same data and model as in the previous notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e14e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"x\": [9, 14, 21, 28, 42, 57, 63, 70, 79],\n",
    "    \"y\": [8.93, 10.80, 18.59, 22.33, 39.35, 56.11, 61.73, 64.62, 67.08]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d61ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, b1, b2, b3):\n",
    "    return b1 / (1 + np.exp(b2 - b3 * x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761abd1e",
   "metadata": {},
   "source": [
    "## A failing fit\n",
    "\n",
    "Fits and warnings and errors can sometimes change depending on your system and library versions. For me, the following fit gives two warnings:\n",
    "\n",
    "1. RuntimeWarning: overflow encountered in exp\n",
    "2. OptimizeWarning: Covariance of the parameters could not be estimated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab599a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d617c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cdeil/anaconda3/envs/py-model-fit/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/6v/0_6nt0pj07x9xjhd8qzkyy700000gn/T/ipykernel_20821/1918929932.py:1: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, pcov = scipy.optimize.curve_fit(f=model, xdata=df[\"x\"], ydata=df[\"y\"])\n"
     ]
    }
   ],
   "source": [
    "popt, pcov = scipy.optimize.curve_fit(f=model, xdata=df[\"x\"], ydata=df[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61a89e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  38.83777778, -986.43411354,  111.60437184])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5970b378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[inf, inf, inf],\n",
       "       [inf, inf, inf],\n",
       "       [inf, inf, inf]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12e073",
   "metadata": {},
   "source": [
    "In this case our model and cost function only has one `exp` call `np.exp(b2 - b3 *x)` so it's clear that the overflow happened because `b2 - b3 * x` was too large.\n",
    "Also the `pcov` being `inf` makes sense if the optimiser warns that covariance cound not be estimated.\n",
    "\n",
    "But some `popt` was computed. Is it valid? \n",
    "\n",
    "The [scipy.optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) docstring says this:\n",
    "> Raises: RuntimeError: if the least-squares minimization fails. \n",
    "\n",
    "Well, in this case `popt` is not valid. The fit failed and the function didn't raise a `RuntimeError`.\n",
    "\n",
    "**Learning 1: if you get any warnings/errors, don't trust the fit. Fix them.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a69d07",
   "metadata": {},
   "source": [
    "## What's the problem?\n",
    "\n",
    "In this case, and actually it's probably the most common issue of failing fits, the problem is that the initial guess for the parameters `p0` was bad.\n",
    "\n",
    "As stated in the [scipy.optimize.curve_fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html) docstring description of `p0`:\n",
    "> Initial guess for the parameters (length N). If None, then the initial values will all be 1\n",
    "\n",
    "So effectively we were doing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84819b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cdeil/anaconda3/envs/py-model-fit/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/6v/0_6nt0pj07x9xjhd8qzkyy700000gn/T/ipykernel_20821/3188724692.py:2: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, pcov, infodict, msg, ier = scipy.optimize.curve_fit(f=model, xdata=df[\"x\"], ydata=df[\"y\"], p0=p0, full_output=True)\n"
     ]
    }
   ],
   "source": [
    "p0=[1, 1, 1]\n",
    "popt, pcov, infodict, msg, ier = scipy.optimize.curve_fit(f=model, xdata=df[\"x\"], ydata=df[\"y\"], p0=p0, full_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a7a6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fvec': array([ 29.90777778,  28.03777778,  20.24777778,  16.50777778,\n",
       "         -0.51222222, -17.27222222, -22.89222222, -25.78222222,\n",
       "        -28.24222222]),\n",
       " 'nfev': 21,\n",
       " 'fjac': array([[-2.99999999,  0.33333333,  0.33333333,  0.33333333,  0.33333333,\n",
       "          0.33333333,  0.33333333,  0.33333333,  0.33333333],\n",
       "        [ 0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ]]),\n",
       " 'ipvt': array([1, 2, 3], dtype=int32),\n",
       " 'qtf': array([2.08951083e-07, 2.05608333e+01, 1.27708333e+01])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43251228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The relative error between two consecutive iterates is at most 0.000000'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70abd75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3510e",
   "metadata": {},
   "source": [
    "That's pretty cryptic and to me at least not helpful. There's no clear fit success/failure flag or message.\n",
    "\n",
    "**Learning 2: scipy.optimize.curve_fit doesn't help you much to debug failing fits.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c936b95",
   "metadata": {},
   "source": [
    "## Tracing the function calls\n",
    "\n",
    "One thing you can do to undertand what's going on is to trace the optimisation to see the evolution in the parameter estimation.\n",
    "\n",
    "This is something often done in Bayesian frameworks like [pymc](https://www.pymc.io/welcome.html) or MCMC samplers like [emcee](https://emcee.readthedocs.io/en/stable/) or in neural net fitting with [pytorch](https://pytorch.org/) or [tensorflow](https://www.tensorflow.org/).\n",
    "But also some nonlinear optimisation packages like [estimagic](https://estimagic.org/) have this built in.\n",
    "\n",
    "I didn't find a built-in option to do this with scipy or iminuit, and for lmfit I only found a `trace=True` option for [lmfit.conf_interval](https://lmfit.github.io/lmfit-py/confidence.html#confidence-interval-functions) and not the main fit function.\n",
    "\n",
    "Here we just add print statements printing dicts in [JSONL](https://jsonlines.org/) format, but you could write it to a text or SQLite file or in-memory list if you want to capture it as part of the fit results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c57846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, b1, b2, b3):\n",
    "    print({\"b1\": b1, \"b2\": b2, \"b3\": b3})\n",
    "    return b1 / (1 + np.exp(b2 - b3 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b306f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b1': 1, 'b2': 1, 'b3': 1}\n",
      "{'b1': 1.0000000149011612, 'b2': 1.0, 'b3': 1.0}\n",
      "{'b1': 1.0, 'b2': 1.0000000149011612, 'b3': 1.0}\n",
      "{'b1': 1.0, 'b2': 1.0, 'b3': 1.0000000149011612}\n",
      "{'b1': 42.73128723717945, 'b2': -581635.5429887469, 'b3': -75906.38810566434}\n",
      "{'b1': 42.633884317230134, 'b2': -145840.2885663749, 'b3': -27453.125482927248}\n",
      "{'b1': 25.6414233988939, 'b2': 19213.87362083769, 'b3': -2163.986665802865}\n",
      "{'b1': 12.452519069475734, 'b2': 2436.3185266913515, 'b3': -270.42669982149755}\n",
      "{'b1': 6.246235668851631, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n",
      "{'b1': 6.246235761927796, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n",
      "{'b1': 6.246235668851631, 'b2': -986.4340988371698, 'b3': 111.60437183708017}\n",
      "{'b1': 6.246235668851631, 'b2': -986.4341135361835, 'b3': 111.6043735001149}\n",
      "{'b1': 16.742992104834787, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n",
      "{'b1': 16.742992354324812, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n",
      "{'b1': 16.742992104834787, 'b2': -986.4340988371698, 'b3': 111.60437183708017}\n",
      "{'b1': 16.742992104834787, 'b2': -986.4341135361835, 'b3': 111.6043735001149}\n",
      "{'b1': 38.83777770812742, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n",
      "{'b1': 38.837778286855404, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n",
      "{'b1': 38.83777770812742, 'b2': -986.4340988371698, 'b3': 111.60437183708017}\n",
      "{'b1': 38.83777770812742, 'b2': -986.4341135361835, 'b3': 111.6043735001149}\n",
      "{'b1': 38.83777777777778, 'b2': -986.4341135361835, 'b3': 111.60437183708017}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cdeil/anaconda3/envs/py-model-fit/lib/python3.11/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: overflow encountered in exp\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/var/folders/6v/0_6nt0pj07x9xjhd8qzkyy700000gn/T/ipykernel_20821/188195328.py:2: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  popt, pcov = scipy.optimize.curve_fit(f=model, xdata=df[\"x\"], ydata=df[\"y\"], p0=p0)\n"
     ]
    }
   ],
   "source": [
    "p0=[1, 1, 1]\n",
    "popt, pcov = scipy.optimize.curve_fit(f=model, xdata=df[\"x\"], ydata=df[\"y\"], p0=p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae266215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  38.83777778, -986.43411354,  111.60437184])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b51787",
   "metadata": {},
   "source": [
    "We see that the optimiser started by evaluating the function at `p0 = [1, 1, 1]` and then took a step `1.0000000149 = 1.49e-8` in each parameter.\n",
    "\n",
    "Based on that it jumped to completely incorrect parameters where the cost function became `inf`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109b8a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/0_6nt0pj07x9xjhd8qzkyy700000gn/T/ipykernel_20821/3346874278.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(b2 - b3 * df[\"x\"][0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = -581635\n",
    "b3 = -75906\n",
    "np.exp(b2 - b3 * df[\"x\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07079ff",
   "metadata": {},
   "source": [
    "Somehow the optimiser then jumps to `b2` and `b3` values where the `exp` evaluates to `0` and thus the model `y = b1 / (1 + np.exp(b2 - b3 * x))` effectively becomes `y = b1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3ecd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = -986\n",
    "b3 = 111\n",
    "np.exp(b2 - b3 * df[\"x\"]).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2433e",
   "metadata": {},
   "source": [
    "**Learning 3: Tracing the optimisation can sometimes give insights which parameters and model parts are the problem.**\n",
    "\n",
    "That said, usually for complex models with many parameters understanding the traces and issues is hard and you'd try other things first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d37b15",
   "metadata": {},
   "source": [
    "## iminuit\n",
    "\n",
    "Let's remove the print statements and tracing from our model and see what iminuit does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06aa029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same failing fit with iminuit and show how it gives a better status and diagnostics with likelihood profile curves\n",
    "# Show common ways to fix the issue: (a) better starting value  (b) use bounds (c) fix/release parameters (d) grid search followed by migrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f336a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, b1, b2, b3):\n",
    "    return b1 / (1 + np.exp(b2 - b3 * x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04114a25",
   "metadata": {},
   "source": [
    "## Bad models\n",
    "\n",
    "* Problem: Highly correlated parameters or fully degenerated parameters\n",
    "* Solution: Choose model with fewer or different parameters or simply fix some."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "451dfa4671af3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create example fitting a + bx + c with degenerate a and c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e5f39a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show badly parameterised example and how equivalent re-parametrisation makes things simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30faaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add second example of fitting step function location that results in flat minimum area.\n",
    "\n",
    "def step_model(x, x_step, amplitude):\n",
    "    return np.where(x > x_step, amplitude, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a655c0f",
   "metadata": {},
   "source": [
    "## Summary and conclusions\n",
    "\n",
    "We have seen some failing fits and now understand the typical problems. Lessons learned:\n",
    "\n",
    "* Learning 1: if you get any warnings/errors, don't trust the fit. Fix them.\n",
    "* Learning 2: scipy.optimize.curve_fit doesn't help you much to debug failing fits.\n",
    "* Learning 3: Tracing the optimisation can sometimes give insights which parameters and model parts are the problem.\n",
    "* Learning 4: In practice fixing failing fits usually means finding better initial guesses for the parameters or using bounds.\n",
    "* Learning 5: Highly correlated or degnerate model parameters are bad. If possible try to avoid them by re-parametrising your model or fixing some parameters to average reasonable values.\n",
    "\n",
    "Concerning the question if you should use `scipy.optimize` or `iminuit`:\n",
    "\n",
    "* Learning 7: Both are great, and nowadays `scipy.optimize` has more robust optimizers and supports e.g. setting bounds.\n",
    "* Learning 8: Some advantages of `iminuit` remain: (a) fix/free parametrs without touching model code, (b) better fit diagnostics and parameter error estimates, (c) easier to use interactively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25054f9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
